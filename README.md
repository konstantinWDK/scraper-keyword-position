# ğŸ” Keyword Position Scraper - Advanced Edition

**SCRAPER PROFESIONAL DE POSICIONES DE KEYWORDS CON REPORTES AVANZADOS**

Herramienta completa para anÃ¡lisis de posiciones SEO usando Google Custom Search API con sistema de reportes detallados, interfaz moderna y funcionalidades avanzadas.

## ğŸš€ CaracterÃ­sticas Principales

### ğŸ”§ Core Features
âœ… **100% Google API** - Usa Custom Search API oficial de Google  
âœ… **Sin anti-detecciÃ³n** - API oficial = accesos garantizados  
âœ… **Sin proxies** - Google maneja las cuotas internacionalmente  
âœ… **Credenciales persistentes** - API Key y Search Engine ID guardados  
âœ… **API de calidad** - Posiciones reales de resultados de bÃºsqueda  
âœ… **Cuotas claras** - 100 consultas gratis/dÃ­a, costos predecibles  

### ğŸ¨ Interfaz y UX
âœ… **Interfaz Ultra Moderna** - CustomTkinter con diseÃ±o profesional  
âœ… **Tema Oscuro Avanzado** - Colores inspirados en Neil Patel  
âœ… **NavegaciÃ³n por PestaÃ±as** - OrganizaciÃ³n intuitiva de funciones  
âœ… **Indicadores en Tiempo Real** - Progreso, estadÃ­sticas y logs  
âœ… **Controles Inteligentes** - Botones de inicio, parada y reinicio  

### ğŸ“Š Sistema de Reportes Avanzado
âœ… **Reportes JSON Detallados** - Almacenamiento estructurado de sesiones  
âœ… **AnÃ¡lisis EstadÃ­stico** - MÃ©tricas de rendimiento y competencia  
âœ… **ExportaciÃ³n HTML** - Reportes visuales profesionales  
âœ… **GrÃ¡ficos Interactivos** - DistribuciÃ³n de posiciones y anÃ¡lisis  
âœ… **GestiÃ³n de Sesiones** - Historial completo de scraping  

### ğŸ”„ Funcionalidades Avanzadas
âœ… **Auto-guardado** - Sesiones guardadas automÃ¡ticamente
âœ… **Keywords Relacionadas** - Sugerencias de Google Suggest
âœ… **AnÃ¡lisis de Competencia** - IdentificaciÃ³n de dominios top
âœ… **Filtros Inteligentes** - Limpieza y deduplicaciÃ³n automÃ¡tica
âœ… **MÃºltiples Formatos** - ExportaciÃ³n CSV, JSON y Excel

### ğŸ†• **Funcionalidades HÃ­bridas** (NUEVO)
âœ… **IntegraciÃ³n Search Console** - Combina datos reales con scraping
âœ… **Detector de Oportunidades** - Keywords con alto ROI potencial
âœ… **ComparaciÃ³n de Posiciones** - SC vs Scraper en tiempo real
âœ… **Gaps de Contenido** - Identifica keywords sin cobertura
âœ… **Score de Visibilidad** - MÃ©trica combinada de rendimiento SEO
âœ… **SincronizaciÃ³n AutomÃ¡tica** - Keywords de SC a lista de scraping
âœ… **Reportes HÃ­bridos HTML** - AnÃ¡lisis visual profesional
âœ… **Recomendaciones Accionables** - Insights automÃ¡ticos priorizados

ğŸ“– **[Ver documentaciÃ³n completa de funcionalidades hÃ­bridas](HYBRID_FEATURES.md)**

### ğŸ” **AutenticaciÃ³n Mejorada de Search Console** (NUEVO)
âœ… **Auto-Refresh de Tokens** - Sin interrupciones ni re-autenticaciÃ³n
âœ… **Sistema Multi-Cuenta** - MÃºltiples clientes sin re-autenticar
âœ… **ValidaciÃ³n AutomÃ¡tica de URLs** - DetecciÃ³n y correcciÃ³n de formatos
âœ… **CachÃ© Inteligente** - 10-30x mÃ¡s rÃ¡pido en operaciones repetitivas
âœ… **Manejo Robusto de Errores** - Mensajes claros y accionables
âœ… **Logging Profesional** - Visibilidad total de operaciones
âœ… **100% Retrocompatible** - Tu cÃ³digo existente sigue funcionando

ğŸ”’ **[Ver documentaciÃ³n de mejoras de autenticaciÃ³n](AUTH_MEJORAS.md)**  

## ğŸ“¦ InstalaciÃ³n

### Requisitos Previos
- Python 3.8 o superior
- pip (gestor de paquetes de Python)
- ConexiÃ³n a internet

### InstalaciÃ³n de Dependencias
```bash
git clone <tu-repo>
cd scraper-keyword-position
pip install -r requirements.txt
```

### EjecuciÃ³n
```bash
python run_gui.py
```

## ğŸ—ï¸ CompilaciÃ³n a Ejecutable

### Windows
```cmd
cd windows
build_windows.bat
```

### Linux
```bash
cd linux
chmod +x build_linux.sh
./build_linux.sh
```

Los ejecutables se generarÃ¡n en las carpetas `dist/` respectivas.

## âš™ï¸ ConfiguraciÃ³n

### 1. ConfiguraciÃ³n de Google API

Edita `config/.env`:

```env
# ğŸš€ GOOGLE API CONFIGURACIÃ“N
# ObtÃ©n tu API Key: https://console.cloud.google.com/apis/credentials
GOOGLE_API_KEY=tu_api_key_aqui

# ObtÃ©n tu Search Engine ID: https://programmablesearchengine.google.com/controlpanel/all (copia despuÃ©s de 'cx=')
GOOGLE_SEARCH_ENGINE_ID=tu_search_engine_id_aqui

# â¡ï¸ USO DE GOOGLE API (siempre verdadero)
USE_GOOGLE_API=true

# Delays entre keywords (segundos)
MIN_KEYWORD_DELAY=5
MAX_KEYWORD_DELAY=15

# ConfiguraciÃ³n geogrÃ¡fica
DEFAULT_COUNTRY=US
DEFAULT_LANGUAGE=en
PAGES_TO_SCRAPE=1
```

### 2. Obtener Credenciales de Google

#### API Key:
1. Ve a [Google Cloud Console](https://console.cloud.google.com/apis/credentials)
2. Crea un nuevo proyecto o selecciona uno existente
3. Habilita la "Custom Search API"
4. Crea credenciales â†’ API Key
5. Copia la API Key generada

#### Search Engine ID:
1. Ve a [Google Custom Search Engine](https://cse.google.com/)
2. Crea un nuevo motor de bÃºsqueda
3. Configura para buscar en "toda la web"
4. Copia el ID que aparece despuÃ©s de 'cx=' en la URL

## ğŸ”§ Uso de la AplicaciÃ³n

### **Interfaz GrÃ¡fica Moderna**
```bash
python run_gui.py
```

### **ğŸŒŸ Flujo de Trabajo Completo:**

#### 1. **ConfiguraciÃ³n Inicial:**
   - **PestaÃ±a "ğŸ” Google API"**: Configura credenciales
   - Ingresa API Key y Search Engine ID
   - Presiona "**âœ… Validar Credenciales API**"

#### 2. **GestiÃ³n de Keywords:**
   - **PestaÃ±a "ğŸ”‘ Keywords"**: Carga o ingresa keywords
   - Usa "**ğŸ“ Cargar desde Archivo**" (formato: una keyword por lÃ­nea)
   - O ingresa manualmente en el Ã¡rea de texto

#### 3. **ConfiguraciÃ³n Avanzada:**
   - **PestaÃ±a "âš™ï¸ ConfiguraciÃ³n"**: Ajusta parÃ¡metros
   - Configura delays entre consultas
   - Establece dominio objetivo (opcional)
   - Ajusta configuraciÃ³n geogrÃ¡fica

#### 4. **EjecuciÃ³n del Scraping:**
   - **PestaÃ±a "ğŸš€ Scraping"**: Controla el proceso
   - "**ğŸ§ª Probar API**": Valida configuraciÃ³n
   - "**ğŸš€ Iniciar Scraping**": Comienza anÃ¡lisis
   - "**â¹ï¸ Detener**": Para el proceso
   - "**ğŸ”„ Reiniciar**": Reinicia scraping

#### 5. **AnÃ¡lisis de Resultados:**
   - **PestaÃ±a "ğŸ“Š Resultados"**: Visualiza datos
   - Tabla interactiva con posiciones encontradas
   - EstadÃ­sticas en tiempo real
   - ExportaciÃ³n a mÃºltiples formatos

#### 6. **Sistema de Reportes:**
   - **PestaÃ±a "ğŸ“‹ Reportes"**: Gestiona sesiones
   - Historial completo de scraping
   - Reportes HTML profesionales
   - AnÃ¡lisis estadÃ­stico avanzado

### **ğŸ’¡ Funcionalidades Avanzadas:**

#### Auto-guardado Inteligente:
- Cada sesiÃ³n se guarda automÃ¡ticamente
- Reportes JSON con metadatos completos
- RecuperaciÃ³n de sesiones interrumpidas

#### AnÃ¡lisis de Competencia:
- IdentificaciÃ³n automÃ¡tica de dominios competidores
- DistribuciÃ³n de posiciones por dominio
- MÃ©tricas de rendimiento comparativo

#### Keywords Relacionadas:
- Sugerencias automÃ¡ticas de Google Suggest
- ExpansiÃ³n inteligente de keywords
- Filtrado y deduplicaciÃ³n automÃ¡tica

## ğŸ“ Estructura del Proyecto

```
scraper-keyword-position/
â”œâ”€â”€ run_gui.py                    # ğŸš€ Punto de entrada principal
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ gui.py                    # Interfaz grÃ¡fica moderna con CustomTkinter
â”‚   â”œâ”€â”€ stealth_scraper.py        # Motor de scraping con Google API
â”‚   â”œâ”€â”€ utils.py                  # Utilidades y anÃ¡lisis de datos
â”‚   â”œâ”€â”€ reports.py                # Sistema de reportes y anÃ¡lisis
â”‚   â””â”€â”€ report_methods.py         # MÃ©todos de gestiÃ³n de reportes
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ .env                      # ConfiguraciÃ³n de credenciales API
â”‚   â””â”€â”€ settings.py               # Gestor de configuraciÃ³n centralizada
â”œâ”€â”€ data/                         # Directorio de resultados exportados
â”‚   â”œâ”€â”€ sessions/                 # Reportes JSON de sesiones
â”‚   â”œâ”€â”€ exports/                  # Archivos CSV y Excel exportados
â”‚   â””â”€â”€ html_reports/             # Reportes HTML generados
â”œâ”€â”€ logs/                         # Logs detallados del scraper
â”œâ”€â”€ windows/                      # Build para Windows
â”‚   â”œâ”€â”€ build_windows.bat         # Script de compilaciÃ³n automÃ¡tica
â”‚   â”œâ”€â”€ scraper.spec              # ConfiguraciÃ³n PyInstaller
â”‚   â””â”€â”€ README_BUILD.md           # Instrucciones de compilaciÃ³n
â”œâ”€â”€ linux/                       # Build para Linux
â”‚   â”œâ”€â”€ build_linux.sh            # Script de compilaciÃ³n automÃ¡tica
â”‚   â”œâ”€â”€ scraper.spec              # ConfiguraciÃ³n PyInstaller
â”‚   â””â”€â”€ README_BUILD.md           # Instrucciones de compilaciÃ³n
â”œâ”€â”€ keywords_ejemplo.txt          # Keywords de ejemplo para testing
â”œâ”€â”€ requirements.txt              # Dependencias del proyecto
â””â”€â”€ README.md                     # Esta documentaciÃ³n completa
```

## ğŸ” Arquitectura y Funcionamiento

### **ğŸ“‹ Google Custom Search API - Funcionamiento TÃ©cnico**

Este scraper utiliza la **Google Custom Search JSON API** para obtener resultados de bÃºsqueda idÃ©nticos a Google.com:

#### **1. ğŸš€ Proceso de Scraping:**

1. **AutenticaciÃ³n API:** ValidaciÃ³n de credenciales Google
2. **Consulta Estructurada:** Llamadas REST con parÃ¡metros geogrÃ¡ficos
3. **Procesamiento JSON:** AnÃ¡lisis de respuestas estructuradas
4. **CÃ¡lculo de Posiciones:** AsignaciÃ³n secuencial de rankings
5. **Auto-guardado:** Almacenamiento automÃ¡tico en mÃºltiples formatos

#### **2. ğŸ“Š Flujo de Datos:**

```mermaid
graph TD
    A[Keywords Input] --> B[Google API Call]
    B --> C[JSON Response]
    C --> D[Position Calculation]
    D --> E[Data Processing]
    E --> F[Auto-save Session]
    F --> G[Generate Reports]
    G --> H[Export Multiple Formats]
```

#### **3. ğŸ¯ Ventajas TÃ©cnicas:**

âœ… **PrecisiÃ³n Garantizada:**
- Resultados idÃ©nticos a Google.com
- Posiciones calculadas matemÃ¡ticamente
- Sin interferencia de personalizaciÃ³n

âœ… **Escalabilidad:**
- Cuotas predecibles (100 gratis/dÃ­a)
- Sin lÃ­mites de velocidad agresivos
- Procesamiento batch eficiente

âœ… **Confiabilidad:**
- API oficial de Google
- Sin riesgo de bloqueos
- Uptime garantizado por Google
- DependÃ­a del navegador y proxies
- Mayor riesgo de bloqueo

## ğŸ“Š Formatos de Salida

### CSV
```csv
keyword,position,title,url,domain,page,snippet
"marketing digital",3,"CÃ³mo Hacer Marketing Digital - GuÃ­a Completa","https://example.com/guia","example.com",1,"Aprende todas las tÃ©cnicas..."
```

### JSON
```json
[
  {
    "keyword": "marketing digital",
    "position": 3,
    "title": "CÃ³mo Hacer Marketing Digital - GuÃ­a Completa",
    "url": "https://example.com/guia",
    "domain": "example.com",
    "page": 1,
    "snippet": "Aprende todas las tÃ©cnicas de marketing digital en este guide completo..."
  }
]
```

## ğŸ” AnÃ¡lisis de Resultados

En la aplicaciÃ³n grÃ¡fica, ve a pestaÃ±a "**ğŸ“ˆ AnÃ¡lisis**" para generar grÃ¡ficos automÃ¡ticamente:

### MÃ©tricas incluidas:
- ğŸ“Š **DistribuciÃ³n de posiciones** - TOP 3, TOP 10, distribuciÃ³n general
- ğŸ† **Top dominios** - Mejores posiciones por dominio
- ğŸ“ˆ **Resultados por pÃ¡gina** - Crecimiento de posiciones paginadas
- ğŸ’¡ **Boxplot de posiciones** - EstadÃ­sticas visuales
- ğŸ… **Ranking por keywords** - Mejores posiciones por tÃ©rmino

### ExportaciÃ³n automÃ¡tica:
- **CSV** y **JSON** con mÃ©tricas completas
- GrÃ¡ficos de distribuciÃ³n disponibles
- HistÃ³ricos de posiciones por dominio

## ğŸš¨ Notas Importantes

### âš–ï¸ Uso Responasable con Google API
- âœ… **Recomendado** - API oficial de Google
- ğŸ“Š **Cuotas transparentes** - 100 consultas/dÃ­a gratis
- ğŸ”’ **Sin bloqueos** - API garantizada
- ğŸ’° **Costos claros** - $5 por cada 1000 consultas adicionales

### ğŸ“¢ Recordatorios de API
- **ğŸ”‘ API Key** segura - No shares tu clave
- **âš¡ Rate Limiting** - Respeta los lÃ­mites de Google
- **ğŸŒ GeolocalizaciÃ³n** - Resultados por paÃ­s/idioma
- **ğŸ”„ Cuotas reset** - Se rellenan cada dÃ­a

### ğŸ’¡ Recomendaciones por Volumen
```python
# Para PROYECTOS PEQUEÃ‘OS (â‰¤100 keywords/dÃ­a):
â¡ï¸ Configurar delays 5-15s (predeterminado)
â¡ï¸ Ideal para clientes personales

# Para CAMPANÃAS MEDIANAS (100-500 keywords/dÃ­a):
â¡ï¸ Ubgrapes 100 consultas gratis diarias
â¡ï¸ Usar delays de 2-5s

# Para EMPRESAS GRANDES (>500 keywords/dÃ­a):
â¡ï¸ Solo keywords estratÃ©gicas
â¡ï¸ $5 por cada 1000 consultas adicionales
```

### ğŸ”§ SoluciÃ³n de Problemas

#### ğŸ” Problemas de Credenciales
**"Sin API Key/Modelo Search Engine ID"**
- âœ… Verifica la pestaÃ±a "**ğŸ” Google API**"
- âœ… AsegÃºrate que la API Key empiece por `AIza`...
- âœ… El Search Engine ID debe ser similar a `e1afc530d3cd24be5`

**"Error 403: Forbidden"**
- âœ… El Search Engine ID no coincide con tu API Key
- âœ… Verifica que ambas credenciales sean de la misma cuenta

#### ğŸ“Š Problemas de Cuotas Google
**"DAILY_LIMIT_EXCEEDED"**
- âœ… Has agotado las 100 consultas diarias gratis
- âœ… Espera al dÃ­a siguiente para reset automÃ¡tico
- âœ… O actualiza a plan pago

**"429: Too Many Requests"**
- âœ… Google estÃ¡ limitando temporalmente
- âœ… Espera unos minutos y continÃºa
- âœ… Reduce la frecuencia de consultas

#### ğŸ” Problemas de Resultados
**"Sin resultados encontrados"**
- âœ… La keyword es demasiado especÃ­fica
- âœ… El paÃ­s/idioma puede no tener resultados
## ğŸš¨ SoluciÃ³n de Problemas

### **ğŸ”§ Problemas Comunes de API**

#### **"API Key invÃ¡lida"**
- âœ… Verifica que la API Key estÃ© correcta en `config/.env`
- âœ… AsegÃºrate de haber habilitado Custom Search API en Google Cloud Console
- âœ… Revisa que no haya espacios extra en la configuraciÃ³n

#### **"Search Engine ID invÃ¡lido"**
- âœ… Verifica el ID en [Google Custom Search Engine](https://cse.google.com/)
- âœ… AsegÃºrate de que el motor estÃ© configurado para "toda la web"
- âœ… Copia el ID completo despuÃ©s de 'cx=' en la URL

#### **"Cuota excedida"**
- âœ… Google API permite 100 consultas gratis por dÃ­a
- âœ… Revisa tu uso en [Google Cloud Console](https://console.cloud.google.com/)
- âœ… Considera habilitar facturaciÃ³n para mÃ¡s cuotas

### **ğŸ“Š Problemas de Resultados**

#### **"No se encuentran posiciones"**
- âœ… Verifica que el dominio objetivo estÃ© en los primeros 100 resultados
- âœ… Prueba con keywords mÃ¡s genÃ©ricos
- âœ… Revisa la configuraciÃ³n geogrÃ¡fica (paÃ­s/idioma)

#### **"Posiciones inconsistentes"**
- âœ… Google API puede dar resultados diferentes por geolocalizaciÃ³n
- âœ… Las posiciones varÃ­an segÃºn personalizaciÃ³n y ubicaciÃ³n
- âœ… Usa configuraciÃ³n geogrÃ¡fica consistente

### **ğŸ–¥ï¸ Problemas TÃ©cnicos**

#### **"Error al iniciar la aplicaciÃ³n"**
- âœ… AsegÃºrate de tener Python 3.8+ instalado
- âœ… Instala dependencias: `pip install -r requirements.txt`
- âœ… Verifica CustomTkinter: `pip install customtkinter`

#### **"Error de conexiÃ³n"**
- âœ… Verifica tu conexiÃ³n a internet: `ping google.com`
- âœ… Revisa configuraciÃ³n de proxy/firewall
- âœ… Intenta desde otra red si es posible

#### **"Reportes no se generan"**
- âœ… Verifica permisos de escritura en directorio `data/`
- âœ… AsegÃºrate de tener espacio en disco suficiente
- âœ… Revisa logs en `logs/scraper.log` para errores especÃ­ficos

## ğŸ“ˆ Roadmap y Futuras Mejoras

### **ğŸ¯ PrÃ³ximas Versiones**
- [ ] **Dashboard Web**: Interfaz web para anÃ¡lisis remoto
- [ ] **API REST**: Endpoints para integraciÃ³n con otras herramientas
- [ ] **Base de Datos**: PostgreSQL/MySQL para almacenamiento persistente
- [ ] **Scraping Programado**: Tareas automÃ¡ticas con cron/scheduler
- [ ] **Alertas Inteligentes**: Notificaciones por email/Slack
- [ ] **AnÃ¡lisis Competitivo**: ComparaciÃ³n automÃ¡tica con competidores

### **ğŸ”§ Mejoras TÃ©cnicas**
- [ ] **MÃºltiples APIs**: IntegraciÃ³n con SerpAPI, DataForSEO
- [ ] **Machine Learning**: PredicciÃ³n de tendencias de posiciones
- [ ] **ExportaciÃ³n Avanzada**: PowerBI, Tableau, Google Sheets
- [ ] **Monitoreo 24/7**: Tracking continuo de posiciones
- [ ] **Multi-idioma**: Soporte para mÃºltiples idiomas
- [ ] **Clustering**: AgrupaciÃ³n inteligente de keywords

## ğŸ¤ Contribuir al Proyecto

### **ğŸš€ CÃ³mo Contribuir**
1. **Fork** el repositorio
2. **Crea una branch**: `git checkout -b feature/nueva-funcionalidad`
3. **Desarrolla** tu funcionalidad con tests
4. **Commit** cambios: `git commit -am 'AÃ±adir nueva funcionalidad'`
5. **Push** branch: `git push origin feature/nueva-funcionalidad`
6. **Crea Pull Request** con descripciÃ³n detallada

### **ğŸ“‹ Ãreas de ContribuciÃ³n**
- **Frontend**: Mejoras en la interfaz CustomTkinter
- **Backend**: OptimizaciÃ³n del motor de scraping
- **Reportes**: Nuevos formatos y visualizaciones
- **Testing**: Casos de prueba y automatizaciÃ³n
- **DocumentaciÃ³n**: GuÃ­as y tutoriales
- **TraducciÃ³n**: Soporte multi-idioma

## ğŸ“„ Licencia y TÃ©rminos

### **âš–ï¸ Licencia**
Este proyecto estÃ¡ bajo **Licencia MIT** - ver archivo `LICENSE` para detalles.

### **âš ï¸ TÃ©rminos de Uso**
- **Uso Educativo**: DiseÃ±ado para aprendizaje y investigaciÃ³n SEO
- **Responsabilidad**: El usuario es responsable del cumplimiento de ToS
- **LÃ­mites de API**: Respeta las cuotas y lÃ­mites de Google API
- **Uso Ã‰tico**: No uses para spam o actividades maliciosas

## ğŸ’¬ Soporte y Comunidad

### **ğŸ†˜ Obtener Ayuda**
1. **Revisa Logs**: Consulta `logs/scraper.log` para errores detallados
2. **Verifica ConfiguraciÃ³n**: Usa la pestaÃ±a de validaciÃ³n en la GUI
3. **Consulta FAQ**: Revisa esta documentaciÃ³n completa
4. **Abre Issue**: Crea un issue en GitHub con detalles del problema

### **ğŸ“ Canales de Soporte**
- **GitHub Issues**: Para bugs y feature requests
- **DocumentaciÃ³n**: Esta guÃ­a completa
- **Logs Detallados**: Sistema de logging integrado
- **ValidaciÃ³n AutomÃ¡tica**: Herramientas de diagnÃ³stico incluidas

### **ğŸ” InformaciÃ³n de Debug**
Al reportar problemas, incluye:
- VersiÃ³n de Python y sistema operativo
- Contenido de `logs/scraper.log`
- ConfiguraciÃ³n utilizada (sin credenciales)
- Pasos para reproducir el error
- Screenshots de la interfaz si es relevante

---

**ğŸ‰ Â¡Gracias por usar Keyword Position Scraper Advanced Edition!**

**âš ï¸ Disclaimer**: Esta herramienta es para uso educativo y de investigaciÃ³n SEO. El uso responsable y el cumplimiento de los tÃ©rminos de servicio de Google API es responsabilidad del usuario.
