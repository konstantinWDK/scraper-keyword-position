# ğŸ” Keyword Position Scraper - Anti-detecciÃ³n 2025

Scraper avanzado de posiciones de keywords con tÃ©cnicas anti-detecciÃ³n para Google SERP. Alternativa gratuita a ScrapeBox.

## ğŸš€ CaracterÃ­sticas

âœ… **Anti-detecciÃ³n avanzada** - Undetected Chrome, headers rotativos, comportamiento humano  
âœ… **Soporte de proxies** - RotaciÃ³n automÃ¡tica de proxies  
âœ… **Google Suggest** - GeneraciÃ³n de keywords con mÃºltiples fuentes  
âœ… **AnÃ¡lisis de posiciones** - Tracking completo de rankings  
âœ… **ExportaciÃ³n mÃºltiple** - CSV, JSON, anÃ¡lisis estadÃ­stico  
âœ… **ConfiguraciÃ³n flexible** - Delays, paÃ­ses, idiomas personalizables  
âœ… **Interfaz grÃ¡fica** - GUI moderna y fÃ¡cil de usar

## ğŸ“¦ InstalaciÃ³n RÃ¡pida

### InstalaciÃ³n AutomÃ¡tica (Recomendada)
```bash
git clone <tu-repo>
cd scraper-keyword-position
./install
```

### InstalaciÃ³n Manual
```bash
# Solo instalar dependencias (Python ya debe estar instalado)
python setup.py
```

## âš™ï¸ ConfiguraciÃ³n

Edita `config/.env`:

```env
# Proxies (Recomendado para evitar bloqueos)
PROXY_1=user:pass@proxy1.com:8080
PROXY_2=proxy2.com:3128

# Delays (segundos)
MIN_KEYWORD_DELAY=5
MAX_KEYWORD_DELAY=15

# ConfiguraciÃ³n Google
DEFAULT_COUNTRY=US
DEFAULT_LANGUAGE=en
PAGES_TO_SCRAPE=1
```

## ğŸ”§ Uso

### Interfaz GrÃ¡fica (Recomendado)
```bash
python src/gui.py
```

### LÃ­nea de Comandos

```bash
# Modo de prueba
python src/main.py --test

# Keywords especÃ­ficas
python src/main.py --keywords "seo,marketing digital" --domain example.com

# Desde archivo
python src/main.py --keyword-file keywords.txt --domain example.com --pages 2

# Google Suggest
python src/main.py --suggest "marketing" --country ES --language es

# AnÃ¡lisis de resultados
python src/main.py --analyze
```

### Ejemplos Avanzados

```bash
# Scraping mÃºltiples pÃ¡ginas con salida personalizada
python src/main.py --keywords "seo,sem,marketing" --domain midominio.com --pages 3 --output mis_resultados

# Keywords desde archivo con configuraciÃ³n especÃ­fica
python src/main.py --keyword-file keywords.txt --domain ejemplo.com --country ES --language es

# Solo generar keywords (sin scraping)
python src/main.py --suggest "marketing digital" --country ES
```

## ğŸ“ Estructura del Proyecto

```
scraper-keyword-position/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # Script principal
â”‚   â”œâ”€â”€ gui.py              # Interfaz grÃ¡fica
â”‚   â”œâ”€â”€ stealth_scraper.py   # Motor de scraping
â”‚   â””â”€â”€ utils.py             # Utilidades y anÃ¡lisis
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ .env                 # ConfiguraciÃ³n (crear desde .env.example)
â”‚   â”œâ”€â”€ .env.example         # Plantilla de configuraciÃ³n
â”‚   â””â”€â”€ settings.py          # Gestor de configuraciÃ³n
â”œâ”€â”€ data/                    # Resultados exportados
â”œâ”€â”€ logs/                    # Logs del scraper
â”œâ”€â”€ requirements.txt         # Dependencias
â”œâ”€â”€ setup.py                # Instalador de dependencias
â””â”€â”€ install                 # Script de instalaciÃ³n simple
```

## ğŸ“Š Formatos de Salida

### CSV
```csv
keyword,position,title,url,domain,page
"marketing digital",3,"GuÃ­a Marketing Digital","https://example.com/guia","example.com",1
```

### JSON
```json
{
  "keyword": "marketing digital",
  "position": 3,
  "title": "GuÃ­a Marketing Digital",
  "url": "https://example.com/guia",
  "domain": "example.com",
  "page": 1
}
```

## ğŸ” AnÃ¡lisis de Resultados

```bash
# Analizar Ãºltimo archivo
python src/main.py --analyze

# Analizar archivo especÃ­fico
python src/main.py --analyze-file data/positions_ejemplo.csv
```

### MÃ©tricas incluidas:
- PosiciÃ³n promedio y mediana
- DistribuciÃ³n TOP 3, TOP 10, PÃ¡gina 2+
- Ranking por dominio
- Keywords con mejores posiciones

## âš¡ TÃ©cnicas Anti-detecciÃ³n

### ğŸ›¡ï¸ Selenium Stealth
- Undetected ChromeDriver
- Headers realistas rotativos
- User-agents aleatorios
- Window size variable
- JavaScript anti-fingerprinting

### ğŸ”„ Comportamiento Humano
- Delays humanizados variables
- Scroll aleatorio
- Movimientos de mouse
- Pausas micro-aleatorias

### ğŸŒ Proxies
- RotaciÃ³n automÃ¡tica
- Soporte HTTP/HTTPS
- Testing automÃ¡tico
- Fallback sin proxy

## ğŸš¨ Notas Importantes

### âš–ï¸ Uso Responsable
- Solo para investigaciÃ³n legÃ­tima
- Respetar robots.txt
- No sobrecargar servidores
- Cumplir tÃ©rminos de servicio

### ğŸ’¡ Recomendaciones
- Usar proxies premium para volumen alto
- Configurar delays apropiados (5-15s)
- Monitorear logs por bloqueos
- Hacer backups de configuraciÃ³n

### ğŸ”§ Troubleshooting

#### ChromeDriver Issues
```bash
# Actualizar undetected-chromedriver
pip install --upgrade undetected-chromedriver
```

#### Proxy Issues
```bash
# Probar proxies individualmente
python -c "from src.utils import ProxyTester; ProxyTester.test_proxy('tu-proxy:puerto')"
```

#### Rate Limiting
- Aumentar delays en `.env`
- Usar mÃ¡s proxies
- Reducir pÃ¡ginas por keyword

## ğŸ“ˆ Roadmap

- [ ] IntegraciÃ³n con APIs SERP
- [ ] Dashboard web
- [ ] Alertas automÃ¡ticas
- [ ] Base de datos persistente
- [ ] Scraping programado
- [ ] MÃ¡s fuentes de suggest

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una branch (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'AÃ±adir nueva funcionalidad'`)
4. Push branch (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

## ğŸ“„ Licencia

Este proyecto es para uso educativo y de investigaciÃ³n. El usuario es responsable de cumplir con los tÃ©rminos de servicio de los sitios web scrapeados.

## ğŸ’¬ Soporte

Si encuentras issues:
1. Revisa los logs en `logs/scraper.log`
2. Verifica la configuraciÃ³n con `--config`
3. Prueba con `--test`
4. Abre un issue con detalles del error

---

**âš ï¸ Disclaimer**: Este scraper es para uso educativo y de investigaciÃ³n. El uso responsable es responsabilidad del usuario.
